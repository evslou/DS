{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 1,
    "id": "kr9vAeEQlRVG"
   },
   "source": [
    "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 3,
    "id": "BxX49gLclRVJ"
   },
   "source": [
    "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±—É—á–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ë—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º, –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–≥–æ —Ä–∞—Å–∫—Ä—ã–≤–∞—Ç—å –Ω–µ –±—É–¥–µ–º. –ú–æ–∂–µ—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤ –µ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–µ. –í –Ω—ë–º 200 –∫–ª–∞—Å—Å–æ–≤ –∏ –æ–∫–æ–ª–æ 5 —Ç—ã—Å—è—á –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–∞ –∫–∞–∂–¥—ã–π –∫–ª–∞—Å—Å. –ö–ª–∞—Å—Å—ã –ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω—ã, –∫–∞–∫ –Ω–µ—Ç—Ä—É–¥–Ω–æ –¥–æ–≥–∞–¥–∞—Ç—å—Å—è, –æ—Ç 0 –¥–æ 199. –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –º–æ–∂–Ω–æ –≤–æ—Ç [—Ç—É—Ç](https://yadi.sk/d/BNR41Vu3y0c7qA).\n",
    "\n",
    "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –ø—Ä–æ—Å—Ç–∞—è -- –µ—Å—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ train/ –∏ val/, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –ª–µ–∂–∞—Ç –æ–±—É—á–∞—é—â–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –í train/ –∏ val/ –ª–µ–∂–∞—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–ª–∞—Å—Å–∞–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –ª–µ–∂–∞—Ç, —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ, —Å–∞–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n",
    " \n",
    "__–ó–∞–¥–∞–Ω–∏–µ__. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–≤–∞ –∑–∞–¥–∞–Ω–∏—è\n",
    "\n",
    "1) –î–æ–±–µ–π—Ç–µ—Å—å accuracy **–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–µ –º–µ–Ω–µ–µ 0.44**. –í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ **–∑–∞–ø—Ä–µ—â–µ–Ω–æ** –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –∏ —Ä–µ—Å–∞–π–∑–æ–º –∫–∞—Ä—Ç–∏–Ω–æ–∫. 5 –±–∞–ª–ª–æ–≤\n",
    "\n",
    "2) –î–æ–±–µ–π—Ç–µ—Å—å accuracy **–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–µ –º–µ–Ω–µ–µ 0.84**. –í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –¥–µ–ª–∞—Ç—å —Ä–µ—Å–∞–π–∑ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ—Ç—Ä–µ–π–Ω –º–æ–∂–Ω–æ. 5 –±–∞–ª–ª–æ–≤\n",
    "\n",
    "–ù–∞–ø–∏—à–∏—Ç–µ –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á—ë—Ç –æ –ø—Ä–æ–¥–µ–ª–∞–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö. –ß—Ç–æ —Å—Ä–∞–±–æ—Ç–∞–ª–æ –∏ —á—Ç–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ? –ü–æ—á–µ–º—É –≤—ã —Ä–µ—à–∏–ª–∏, —Å–¥–µ–ª–∞—Ç—å —Ç–∞–∫, –∞ –Ω–µ –∏–Ω–∞—á–µ? –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑—ã–≤–∞–π—Ç–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —á—É–∂–æ–π –∫–æ–¥, –µ—Å–ª–∏ –≤—ã –µ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ. –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å—Å—ã–ª–∞–π—Ç–µ—Å—å –Ω–∞ —Å—Ç–∞—Ç—å–∏ / –±–ª–æ–≥–ø–æ—Å—Ç—ã / –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ stackoverflow / –≤–∏–¥–æ—Å—ã –æ—Ç —é—Ç—É–±–µ—Ä–æ–≤-–º–∞—à–∏–Ω–ª–µ—Ä–Ω–µ—Ä–æ–≤ / –∫—É—Ä—Å—ã / –ø–æ–¥—Å–∫–∞–∑–∫–∏ –æ—Ç –î—è–¥–∏ –í–∞—Å–∏ –∏ –ø—Ä–æ—á–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –µ—Å–ª–∏ –≤—ã –∏—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ. \n",
    "\n",
    "–í–∞—à –∫–æ–¥ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–µ–Ω –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –≤—Å–µ `assert`'—ã –Ω–∏–∂–µ.\n",
    "\n",
    "__–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ –≤ –æ–±–æ–∏—Ö –∑–∞–¥–∞–Ω–∏—è—Ö. –¢–∞–∫–∂–µ –∑–∞–ø—Ä–µ—â–µ–Ω–æ –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ__.\n",
    "\n",
    "\n",
    "__–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏__: –û—Ü–µ–Ω–∫–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –ø–æ –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º—É–ª–µ: `min(10, 10 * –í–∞—à–∞ accuracy / 0.44)` –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –∏ `min(10, 10 * (–í–∞—à–∞ accuracy - 0.5) / 0.34)` –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ. –û—Ü–µ–Ω–∫–∞ –æ–∫—Ä—É–≥–ª—è–µ—Ç—Å—è –¥–æ –¥–µ—Å—è—Ç—ã—Ö –ø–æ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–∏–º –ø—Ä–∞–≤–∏–ª–∞–º.\n",
    "\n",
    "\n",
    "__–°–æ–≤–µ—Ç—ã –∏ —É–∫–∞–∑–∞–Ω–∏—è__:\n",
    " - –ù–∞–≤–µ—Ä–Ω—è–∫–∞ –≤–∞–º –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –º–Ω–æ–≥–æ –≥—É–≥–ª–∏—Ç—å –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –æ —Ç–æ–º, –∫–∞–∫ –∑–∞—Å—Ç–∞–≤–∏—Ç—å –µ—ë —Ä–∞–±–æ—Ç–∞—Ç—å. –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –≤—Å–µ –≥—É–≥–ª—è—Ç. –ù–æ –Ω–µ –∑–∞–±—ã–≤–∞–π—Ç–µ, —á—Ç–æ –Ω—É–∂–Ω–æ –±—ã—Ç—å –≥–æ—Ç–æ–≤—ã–º –∑–∞ —Å–∫–∞—Ç–∞–Ω–Ω—ã–π –∫–æ–¥ –æ—Ç–≤–µ—á–∞—Ç—å :)\n",
    " - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏. –î–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –º–æ–¥—É–ª–µ–º `torchvision.transforms` –∏–ª–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π [albumentations](https://github.com/albumentations-team/albumentations)\n",
    " - –ú–æ–∂–Ω–æ –æ–±—É—á–∞—Ç—å —Å –Ω—É–ª—è –∏–ª–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏—Ç—å (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞–Ω–∏—è) –º–æ–¥–µ–ª–∏ –∏–∑ `torchvision`.\n",
    " - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –Ω–∞–ø–∏—Å–∞—Ç—å –≤–∞–º —Å–Ω–∞—á–∞–ª–∞ –∫–ª–∞—Å—Å-–¥–∞—Ç–∞—Å–µ—Ç (–∏–ª–∏ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–ª–∞—Å—Å–æ–º `ImageFolder`), –∫–æ—Ç–æ—Ä—ã–π –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–º –∫–ª–∞—Å—Å—ã, –∞ –∑–∞—Ç–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ç—Ä–µ–π–Ω–∞ –ø–æ —à–∞–±–ª–æ–Ω–∞–º –Ω–∏–∂–µ. –û–¥–Ω–∞–∫–æ –¥–µ–ª–∞—Ç—å —ç—Ç–æ –º—ã –Ω–µ –∑–∞—Å—Ç–∞–≤–ª—è–µ–º. –ï—Å–ª–∏ –≤–∞–º —Ç–∞–∫ –Ω–µ—É–¥–æ–±–Ω–æ, —Ç–æ –º–æ–∂–µ—Ç–µ –ø–∏—Å–∞—Ç—å –∫–æ–¥ –≤ —É–¥–æ–±–Ω–æ–º —Å—Ç–∏–ª–µ. –û–¥–Ω–∞–∫–æ —É—á—Ç–∏—Ç–µ, —á—Ç–æ —á—Ä–µ–∑–º–µ—Ä–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–∏–∂–µ–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö —à–∞–±–ª–æ–Ω–æ–≤ —É–≤–µ–ª–∏—á–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –∫ –≤–∞—à–µ–º—É –∫–æ–¥—É –∏ –ø–æ–≤—ã—Å–∏—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã–∑–æ–≤–∞ –Ω–∞ –∑–∞—â–∏—Ç—É :)\n",
    " - –í–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ. –¢—Ä–µ–∫–∞–π—Ç–µ –æ—à–∏–±–∫–∏ –∫–∞–∫ –º–æ–∂–Ω–æ —Ä–∞–Ω—å—à–µ, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –≤–ø—É—Å—Ç—É—é.\n",
    " - –ß—Ç–æ–±—ã –±—ã—Å—Ç—Ä–æ –æ—Ç–ª–∞–¥–∏—Ç—å –∫–æ–¥, –ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –º–∞–ª–µ–Ω—å–∫–æ–π —á–∞—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ (—Å–∫–∞–∂–µ–º, 5-10 –∫–∞—Ä—Ç–∏–Ω–æ–∫ –ø—Ä–æ—Å—Ç–æ —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –∫–æ–¥ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è). –ö–æ–≥–¥–∞ –≤—ã –ø–æ–Ω—è–ª–∏, —á—Ç–æ —Å–º–æ–≥–ª–∏ –≤—Å—ë –æ—Ç–¥–µ–±–∞–∂–∏—Ç—å, –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –æ–±—É—á–µ–Ω–∏—é –ø–æ –≤—Å–µ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    " - –ù–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—É—Å–∫ –¥–µ–ª–∞–π—Ç–µ —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –º–æ–¥–µ–ª–∏/–∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏/–æ–ø—Ç–∏–º–∞–π–∑–µ—Ä–µ, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, —á—Ç–æ –∏ –∫–∞–∫ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\n",
    " - –§–∏–∫—Å–∏—Ä—É–π—Ç–µ random seed.\n",
    " - –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø—Ä–æ—Å—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π –∏ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ —Å–ª–æ–∂–Ω—ã–º. –û–±—É—á–µ–Ω–∏–µ –ª—ë–≥–∫–∏—Ö –º–æ–¥–µ–ª–µ–π —ç–∫–æ–Ω–æ–º–∏—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.\n",
    " - –°—Ç–∞–≤—å—Ç–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ learning rate. –£–º–µ–Ω—å—à–∞–π—Ç–µ –µ–≥–æ, –∫–æ–≥–¥–∞ –ª–æ—Å—Å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–µ—Ä–µ—Å—Ç–∞—ë—Ç —É–±—ã–≤–∞—Ç—å.\n",
    " - –°–æ–≤–µ—Ç—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU. –ï—Å–ª–∏ —É –≤–∞—Å –µ–≥–æ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ google colab. –ï—Å–ª–∏ –≤–∞–º –Ω–µ—É–¥–æ–±–Ω–æ –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π –æ—Å–Ω–æ–≤–µ, –Ω–∞–ø–∏—à–∏—Ç–µ –∏ –æ—Ç–ª–∞–¥—å—Ç–µ –≤–µ—Å—å –∫–æ–¥ –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ CPU, –∞ –∑–∞—Ç–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç–µ —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–π –Ω–æ—É—Ç–±—É–∫ –≤ –∫–æ–ª–∞–±–µ. –ê–≤—Ç–æ—Ä—Å–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —Ç—Ä–µ–±—É–µ–º–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ –∫–æ–ª–∞–±–µ –∑–∞ 15 –º–∏–Ω—É—Ç –æ–±—É—á–µ–Ω–∏—è.\n",
    " \n",
    "Good luck & have fun! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BaPSFxIz96tY"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb\n",
    "# !pip3 install pytorch_lightning torchmetrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ú® –í–Ω–∏–º–∞–Ω–∏–µ ‚ú®**\n",
    "\n",
    "–í —ç—Ç–æ–º –¥–æ–º–∞—à–Ω–µ–º –∑–∞–¥–∞–Ω–∏–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É `pytorch_lightning`. –î–æ—Å—Ç—É–ø –∫ –µ–µ [–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏](https://lightning.ai/docs/pytorch/stable/) –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω —Å —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏ –†–§. –í—ã –º–æ–∂–µ—Ç–µ:\n",
    "\n",
    "1. –ü–æ–ª—É—á–∏—Ç—å –∫ –Ω–µ–π –¥–æ—Å—Ç—É–ø —Å –ø–æ–º–æ—â—å—é VPN.\n",
    "\n",
    "2. –°–æ–±—Ä–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ. –î–ª—è —ç—Ç–æ–≥–æ —Å–∫–ª–æ–Ω–∏—Ä—É–π—Ç–µ [github-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/Lightning-AI/lightning/tree/master), –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤ –Ω–µ–º —Ç–µ—Ä–º–∏–Ω–∞–ª (–Ω–∞ windows ‚Äì git bash) –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—ã:\n",
    "\n",
    "```shell\n",
    "git submodule update --init --recursive\n",
    "make docs\n",
    "```\n",
    "–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –æ—Ç–∫—Ä–æ–π—Ç–µ –ø–æ—è–≤–∏–≤—à–∏–π—Å—è —Ñ–∞–π–ª `docs/build/html/index.html`. –î–ª—è —Ä–∞–±–æ—Ç—ã –∫–æ–º–∞–Ω–¥ –≤ –≤–∞—à–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å `pip`. –ü–æ–ª–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è [–ø–æ —Å—Å—ã–ª–∫–µ](https://github.com/Lightning-AI/lightning/tree/master/docs).\n",
    "\n",
    "3. –ì—É–≥–ª–∏—Ç—å `<error message> pytorch lightning` –∏–ª–∏ `<how to do this> pytorch lightning`. Stack overflow –Ω–∞ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏ –†–§ –≤—Å–µ –µ—â–µ –¥–æ—Å—Ç—É–ø–µ–Ω üòâ\n",
    "\n",
    "4. –ù–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è `pytorch_lightning` –∏ –Ω–∞–ø–∏—Å–∞—Ç—å —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ. –ù–∞–ø—Ä–∏–º–µ—Ä, –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å —Ñ—É–Ω–∫—Ü–∏–µ–π `fit` –∏–∑ [—Å–µ–º–∏–Ω–∞—Ä–∞ 4](https://github.com/hse-ds/iad-deep-learning/blob/master/2023/seminars/04.%20Optim%20%26%20Lightning/04_Optim%26Lightning_solution.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EWT3aFU9XmLJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaevseev-work\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –í–æ–∑–º–æ–∂–Ω–æ –Ω–∏–∂–µ –±—É–¥–µ—Ç –Ω–µ –æ—á–µ–Ω—å —Ä–∞–±–æ—Ç–∞—Ç—å WandbLogger —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑—É, –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel —Ç–µ—Ç—Ä–∞–¥–∫–∏\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 4,
    "id": "LKcSNj4tlRVK"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "from lion_pytorch import Lion\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR\n",
    "\n",
    "# You may add any imports you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "47YPLjDL-Mtv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 13\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    # –§–∏—Å–∫–∏—Ä—É–µ—Ç –º–∞–∫—Å–∏–º—É–º —Å–∏–¥–æ–≤.\n",
    "    # –≠—Ç–æ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ –±—ã–ª–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.random.manual_seed(seed)\n",
    "    pl.seed_everything(seed=seed)\n",
    "\n",
    "seed_everything(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RytEDW0ylRVN"
   },
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HZECedTvepi"
   },
   "source": [
    "### –ß—Ç–æ –ø–æ–º–æ–∂–µ—Ç —Å–¥–µ–ª–∞—Ç—å –Ω–∞ 10 –∏–∑ 10 (–æ–¥–Ω–æ –∑–∞–¥–∞–Ω–∏–µ - 5 –±–∞–ª–ª–æ–≤)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOioHGEiveso"
   },
   "source": [
    "1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ —ç–∫—Å–ø–µ—Ä–µ–º–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å –Ω–∏–º–∏.\n",
    "2. –ü–æ–¥–±–æ—Ä learning rate. –ü—Ä–∏–º–µ—Ä –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ —Å–µ–º–∏–Ω–∞—Ä–∞ –∫–∞–∫ —ç—Ç–æ –¥–µ–ª–∞—Ç—å: [–ö–∞–∫ –Ω–∞–π—Ç–∏ lr](https://pytorch-lightning.readthedocs.io/en/1.4.5/advanced/lr_finder.html)\n",
    "\n",
    "```\n",
    "  trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=2, auto_lr_find=True) \n",
    "\n",
    "  trainer.tune(module, train_dataloader, eval_dataloader)\n",
    "\n",
    "  trainer.fit(module, train_dataloader, eval_dataloader))\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "3. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö. [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (–ø–æ–ª–µ–∑–Ω–∞—è)](https://pytorch.org/vision/main/transforms.html), –∞ —Ç–∞–∫–∂–µ [–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ albumentation](https://towardsdatascience.com/getting-started-with-albumentation-winning-deep-learning-image-augmentation-technique-in-pytorch-47aaba0ee3f8)\n",
    "4. –ü–æ–¥–±–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏. \n",
    "5. –ú–æ–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å –º–æ–¥–µ–ª—å —Ä—É–∫–∞–º–∏ —Å–≤–æ—é –≤ YourNet, –∞ –º–æ–∂–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é —Å–µ—Ç–∫—É –∏–∑–≤–µ—Å—Ç–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏–∑ –º–æ–¥—É–ª—è torchvision.models. –û–¥–∏–Ω –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤ –∫–∞–∫ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å: \n",
    "\n",
    "  * `torchvision.models.resnet18(pretrained=False, num_classes=200).to(device)`\n",
    "  * –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –≤–æ–∑–º–æ–∂–Ω—ã–º –º–æ–¥–µ–ª—è–º –∏ –∫–∞–∫ –∏—Ö –º–æ–∂–Ω–æ –±—Ä–∞—Ç—å: [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (–ø–æ–ª–µ–∑–Ω–∞—è)](https://pytorch.org/vision/stable/models.html)\n",
    "6. –ü—Ä–∞–≤–∏–ª—å–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏, –ø—Ä–∏–º–µ—Ä [—Ç—ã–∫, –Ω–æ —Ç—É—Ç –∏ –≤ —Ü–µ–ª–æ–º –≥–∞–π–¥ –æ—Ç –∏ –¥–æ](https://www.pluralsight.com/guides/image-classification-with-pytorch)\n",
    "7. Model Checkpointing. –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Å–≤–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å (–º–æ–¥–µ–ª–∏), —á—Ç–æ–±—ã –∫–æ–≥–¥–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥–µ—Ç –Ω–µ —Ç–∞–∫ –≤—ã —Å–º–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å —Å —ç—Ç–æ–≥–æ –º–µ—Å—Ç–∞ –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Å–≤–æ–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—É—á–∞–ª–∏. \n",
    " * –ü—Ä–∏–º–µ—Ä –∫–∞–∫ –º–æ–∂–Ω–æ —Å wandb —Ç—É—Ç: [–°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –≤ wandb](https://docs.wandb.ai/guides/integrations/lightning)\n",
    " * –ü–æ –ø—Ä–æ—Å—Ç–æ–º—É –º–æ–∂–Ω–æ —Ç–∞–∫: [–°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏ –≤ pytorch –¥–æ–∫–∞](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYePsQgNRB-n"
   },
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_img = transforms.Compose([\n",
    "    transforms.RandomApply(transforms=[transforms.AutoAugment()], p=0.5),\n",
    "    transforms.RandomApply(transforms=[transforms.AugMix()], p=0.5),\n",
    "    transforms.RandomApply(transforms=[transforms.Grayscale(num_output_channels=3)], p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder('/Users/nikitaevseev/Desktop/DS/DL/dataset/dataset/train', transform=transform_img)\n",
    "\n",
    "train_dataset_loader = DataLoader(\n",
    "  train_dataset, \n",
    "  batch_size=len(train_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and std: \n",
      " tensor([0.4681, 0.4489, 0.4170]) tensor([0.2760, 0.2705, 0.2814])\n"
     ]
    }
   ],
   "source": [
    "def mean_std(loader):\n",
    "  images, lebels = next(iter(loader))\n",
    "  mean, std = images.mean([0,2,3]), images.std([0,2,3])\n",
    "  return mean, std\n",
    "mean, std = mean_std(train_dataset_loader)\n",
    "print(\"mean and std: \\n\", mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 5,
    "id": "QEdDQtHdlRVO"
   },
   "outputs": [],
   "source": [
    "# YOU CAN DEFINE AUGMENTATIONS HERE\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomApply(transforms=[transforms.ColorJitter(brightness=1.0, contrast=0.5, saturation=1, hue=0.1)], p=0.2),\n",
    "        transforms.RandomApply(transforms=[transforms.AutoAugment()], p=0.5),\n",
    "        transforms.RandomApply(transforms=[transforms.AugMix()], p=0.2),\n",
    "        transforms.RandomApply(transforms=[transforms.Grayscale(num_output_channels=3)], p=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4681, 0.4489, 0.4170], std=[0.2760, 0.2705, 0.2814])\n",
    "    ]\n",
    ")\n",
    "#(0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)                    [0.485, 0.456, 0.406] [0.229, 0.224, 0.225]\n",
    "# mean=[0.4802, 0.4481, 0.3975], std=[0.2770, 0.2691, 0.2821]\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4681, 0.4489, 0.4170], std=[0.2760, 0.2705, 0.2814])\n",
    "    ]\n",
    ")\n",
    "\n",
    "#applier = transforms.RandomApply(transforms=[AugMix], p=0.5)\n",
    "\n",
    "#transforms = transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(), ]), p=0.3)\n",
    "\n",
    "train_dataset = ImageFolder('/Users/nikitaevseev/Desktop/DS/DL/dataset/dataset/train', transform=train_transform)\n",
    "val_dataset = ImageFolder('/Users/nikitaevseev/Desktop/DS/DL/dataset/dataset/val', transform=val_transform)\n",
    "# REPLACE ./dataset/dataset WITH THE FOLDER WHERE YOU DOWNLOADED AND UNZIPPED THE DATASET\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=7, persistent_workers=True, multiprocessing_context='forkserver')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=7, persistent_workers=True, multiprocessing_context='forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 6,
    "id": "mrg4Yj0VlRVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "# Just very simple sanity checks\n",
    "assert isinstance(train_dataset[0], tuple)\n",
    "assert len(train_dataset[0]) == 2\n",
    "assert isinstance(train_dataset[1][1], int)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOuM0EEYj7Ml"
   },
   "source": [
    "### –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–æ—á–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DeuB0YC3LYRm"
   },
   "outputs": [],
   "source": [
    "for batch in val_dataloader:\n",
    "    images, class_nums = batch\n",
    "    plt.imshow(images[5].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    plt.imshow(images[15].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCwKB-3nKm1-"
   },
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 1. \n",
    "\n",
    "5 –±–∞–ª–ª–æ–≤\n",
    "–î–æ–±–µ–π—Ç–µ—Å—å accuracy –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–µ –º–µ–Ω–µ–µ 0.44. –í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –∑–∞–ø—Ä–µ—â–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –∏ —Ä–µ—Å–∞–π–∑–æ–º –∫–∞—Ä—Ç–∏–Ω–æ–∫.\n",
    "\n",
    "\n",
    "–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –≤—ã–±–∏—Ç—å —Å–∫–æ—Ä (—Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–∏–∂–µ) –Ω–∞ 2.5/5 –±–∞–ª–ª–∞ (—Ç–æ –µ—Å—Ç—å –ø–æ–ª–æ–≤–∏–Ω—É –∑–∞ –∑–∞–¥–∞–Ω–∏–µ) –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–±–ª—é–¥–∞—Ç—å –ø–∞—Ä—É –ø—Ä–æ—Å—Ç—ã—Ö –∂–∏–∑–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª:\n",
    "1. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–±–µ–∑ –Ω–µ–µ —Å–ª–æ–∂–Ω–æ –æ—á–µ–Ω—å –±—É–¥–µ—Ç)\n",
    "2. –û–ø—Ç–∏–º–∞–π–∑–µ—Ä—ã –º–æ–∂–Ω–æ (–∏ –Ω—É–∂–Ω–æ) –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º. –û–¥–Ω–∞–∫–æ –∫–æ–≥–¥–∞ —á—Ç–æ-—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç–µ, —Ç–æ –Ω–µ –º–µ–Ω—è–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—Ä–∞–∑—É - —Å–æ–±—å–µ—Ç–µ –ª–æ–≥–∏–∫—É —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
    "3. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–ª–∏ —Å–∞–º—ã–µ –ø–µ—Ä–≤—ã–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (—á—Ç–æ –Ω–∞ –ª–µ–∫—Ü–∏—è—Ö –≤—Å—Ç—Ä–µ—á–∞–ª–∏—Å—å)\n",
    "4. –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Å–µ –Ω–æ—É—Ç–±—É–∫–∏ –ø—Ä–æ—à–µ–¥—à–∏—Ö —Å–µ–º–∏–Ω–∞—Ä–æ–≤ –∏ —Å–ª–µ–ø–∏—Ç—å –∏–∑ –Ω–∏—Ö —á—Ç–æ-—Ç–æ –æ–±—â–µ–µ. –°–µ–º–∏–Ω–∞—Ä—Å–∫–∏—Ö —Ç–µ—Ç—Ä–∞–¥–æ–∫ —Ö–≤–∞—Ç–∏—Ç —Å–≤–µ—Ä—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWR2l6ymZfRJ"
   },
   "source": [
    "### –ú–æ–¥–µ–ª—å (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –Ω–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mDYorQXLZhTQ"
   },
   "outputs": [],
   "source": [
    "class YourNet(torch.nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.batch_norm1 = torch.nn.BatchNorm2d(16)\n",
    "        self.batch_norm2 = torch.nn.BatchNorm2d(32)\n",
    "        self.batch_norm3 = torch.nn.BatchNorm2d(64)\n",
    "        self.batch_norm4 = torch.nn.BatchNorm1d(128)\n",
    "\n",
    "        self.maxpool = torch.nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 16, 3)\n",
    "        self.conv3 = torch.nn.Conv2d(16, 32, 3)\n",
    "        self.conv4 = torch.nn.Conv2d(32, 32, 3)\n",
    "        self.conv5 = torch.nn.Conv2d(32, 64, 3)\n",
    "        self.conv6 = torch.nn.Conv2d(64, 64, 3)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = torch.nn.Linear(64 * 4 * 4, 128)\n",
    "        self.output = torch.nn.Linear(128, 200)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        # --------------\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "        self.targets = torch.Tensor()\n",
    "        self.preds = torch.Tensor()\n",
    "        pass\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        return self.output(x)\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        # images ~ (batch size, num channels, height, width)\n",
    "        # target ~ (batch size)\n",
    "        # output ~ (batch size, num classes)\n",
    "        output = self._forward(images)\n",
    "\n",
    "        # get accuracy score and save it to self.accuracy\n",
    "        if target is not None:\n",
    "            loss = self.loss_func(output, target)\n",
    "\n",
    "            self.targets = torch.cat((self.targets, target.cpu()), 0)\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            self.preds = torch.cat((self.preds, pred.cpu()), 0)\n",
    "            self.accuracy = accuracy(self.preds.long(), self.targets.long(), task='multiclass', num_classes=200)\n",
    "\n",
    "        return loss if target is not None else output\n",
    "\n",
    "    def get_accuracy(self, reset=False):\n",
    "        # return accuracy by all values till now\n",
    "        if reset:\n",
    "            self.targets = torch.Tensor()\n",
    "            self.preds = torch.Tensor()\n",
    "        return self.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification, ViTModel\n",
    "\n",
    "#processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "#model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "config = ViTModel.from_pretrained(model_name).config\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å–≤–æ–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –∏ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
    "num_classes = 200\n",
    "image_size = 64\n",
    "\n",
    "# –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –≤–∞—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "config.vocab_size = num_classes\n",
    "config.image_size = (image_size, image_size)\n",
    "\n",
    "# –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n",
    "model = ViTForImageClassification(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "# –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å vit-g/14\n",
    "\n",
    "model = transformers.ViTForImageClassification.from_pretrained(\"google/vit-g-14\", pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7iHXWj1alM1"
   },
   "source": [
    "### –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –∫–ª–∞—Å—Å lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–æ–±–∞–≤–∏—Ç—å Learning Rate Finder –∏–∑ lightning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lD76TeZ1apua"
   },
   "outputs": [],
   "source": [
    "class YourModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-4, wd=10.0):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.wd = wd\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.model(x)\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        #optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate*10)\n",
    "        optimizer = Lion(self.parameters(), lr=self.learning_rate, weight_decay=self.wd)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {#LambdaLR(optimizer, lr_lambda=lambda epoch: 0.85 ** epoch)}\n",
    "                \"scheduler\": ReduceLROnPlateau(optimizer, factor=0.1, patience=1),\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"frequency\": 1   \n",
    "                },\n",
    "        }\n",
    "        \n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        images, target = train_batch\n",
    "        output = self.model(images)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, prog_bar=True\n",
    "        )  # —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–≥–∏ –≤ –ø–∞–ø–∫—É, –Ω–æ –º–æ–∂–Ω–æ –Ω–µ—Å–ª–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å wandb\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        images, target = val_batch\n",
    "        #loss = self.model(images, target)\n",
    "        output = self.model(images)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "        acc_batch = accuracy(pred.long(), target, task='multiclass', num_classes=200)\n",
    "        self.log(\"acc\", acc_batch, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False, num_classes=200)\n",
    "\n",
    "checkpoint = torch.load('/Users/nikitaevseev/Desktop/DS/DL/lightning_logs/ye436ozw/checkpoints/epoch=11-step=2352.ckpt')\n",
    "\n",
    "prefix_to_remove = 'model.'\n",
    "new_state_dict = {k.replace(prefix_to_remove, ''): v for k, v in checkpoint['state_dict'].items()}\n",
    "\n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikitaevseev/Desktop/DS/DL/wandb/run-20231104_213555-ye436ozw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/naevseev-work/hw_02_exs1/runs/ye436ozw' target=\"_blank\">resnet18+Lion+entr+512v3-8.15</a></strong> to <a href='https://wandb.ai/naevseev-work/hw_02_exs1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/naevseev-work/hw_02_exs1' target=\"_blank\">https://wandb.ai/naevseev-work/hw_02_exs1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/naevseev-work/hw_02_exs1/runs/ye436ozw' target=\"_blank\">https://wandb.ai/naevseev-work/hw_02_exs1/runs/ye436ozw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger\\\n",
    "    (log_model='all', current_epoch=11) # –∫–∞–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–∞–µ—Ç —Å pytorch_lightning https://docs.wandb.ai/guides/integrations/lightning\n",
    "\n",
    "module = YourModule(model) # YOUR CODE HERE\n",
    "\n",
    "wandb.init(project=\"hw_02_exs1\", id='ye436ozw', resume=True)\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.shufflenet_v2_x2_0(pretrained=False, num_classes=200)\n",
    "#resnet = torchvision.models.resnet18(pretrained=False, num_classes=200)\n",
    "#num_classes = 200  # –ó–∞–¥–∞–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –≤–∞—à–µ–π –∑–∞–¥–∞—á–∏\n",
    "#resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "z9-1wq7QYkiz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikitaevseev/Desktop/DS/DL/wandb/run-20231108_193712-ogj8qp08</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/naevseev-work/hw_02_exs1/runs/ogj8qp08' target=\"_blank\">shufflenet_x2.0+Lion+entr+512+randaug+factor0.1</a></strong> to <a href='https://wandb.ai/naevseev-work/hw_02_exs1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/naevseev-work/hw_02_exs1' target=\"_blank\">https://wandb.ai/naevseev-work/hw_02_exs1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/naevseev-work/hw_02_exs1/runs/ogj8qp08' target=\"_blank\">https://wandb.ai/naevseev-work/hw_02_exs1/runs/ogj8qp08</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger\\\n",
    "    (log_model='all') # –∫–∞–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–∞–µ—Ç —Å pytorch_lightning https://docs.wandb.ai/guides/integrations/lightning\n",
    "\n",
    "model = resnet#YourNet(dropout=0.4)\n",
    "module = YourModule(model) # YOUR CODE HERE\n",
    "\n",
    "name = \"shufflenet_x2.0+Lion+entr+512+randaug+factor0.1\"\n",
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç\n",
    "wandb.init(project=\"hw_02_exs1\", name=name)\n",
    "# —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∫–∏ –≤ wandb + –ø—Ä–æ—Å–∏–º —Å–ª–µ–¥–∏—Ç—å –∑–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ —Å–µ—Ç–∫–∏\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "If8fi4HZkN3J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | ShuffleNetV2 | 5.8 M \n",
      "---------------------------------------\n",
      "5.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.8 M     Total params\n",
      "23.019    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a904fe014f40289cf59aea7e577351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78d5f47cba34c75841ace22b29870f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8f464b26464e9887fd9041c5eac57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a0cde7e81e4e91bee4e17cfdab2a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa15aed78d89461f9753ba961cf5bbb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afb512da883412cae58bad96a828af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bdea8373ae4f3588dec273ba26d1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4399bc79a583443ebcb5a04755c11638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c0b9e5440a4a62b364f56a2619e930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fcb4616f444363833df5ba8bc08f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee68b95b57a84fd1af98c3a81acfd9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c04f6d97ff457b914b8fdd6a37f740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa12a886ffe4581bac5dd173f91f497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbb7ad568f4479bad6f940a8a91869e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb409544b6141eeb1edca7a7545a4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f095c11d9fd64204b1f0481bf8f1a5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598946391e0146ff96435d0002a49ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364651f66ee446cd9beba6a726301aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa440bbfa8240b49cc3beb4ae87073d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304f98d5da5d44489210ed3eb274962a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049d18cb314446509abbaeb1477571da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6f44ec37ec4aaea571a25a03036af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bab905f9d342f7a8d8d03d1cc9c1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e1a6d68bd64a21a996d380d67ce970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4383d9f644a04704886bd5c1fc02073a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a37e048e12f4540a54182b4e7617342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d941f85cc8d04908a9078d29fdab9467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098968f99bad4a6c93f3873b625ed9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a2083a077b4d3cafa7081c9f6d8266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9183490aae4e40b89962aa9610647644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23898f24f1bb473488aa30f2f7e01a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca6fccdcc6f4f5b9e500b52bf02d6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=wandb_logger, max_epochs=30)\n",
    "trainer.fit(module, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eoTAB1fSOuk"
   },
   "source": [
    "### –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–¥–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4M_BAiMNl1rL"
   },
   "outputs": [],
   "source": [
    "def evaluate_task(model, test_dataloader):\n",
    "    model = model\n",
    "    model.eval()\n",
    "    taccuracy = 0.0\n",
    "    for images, labels in tqdm(test_dataloader):\n",
    "        images, labels = images, labels\n",
    "        with torch.no_grad():\n",
    "            #loss = model(images, labels)\n",
    "            output = model(images)\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            targets = labels\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            preds = pred\n",
    "            acc_batch = accuracy(preds.long(), targets.long(), task='multiclass', num_classes=200)\n",
    "        taccuracy += acc_batch\n",
    "    taccuracy = taccuracy / len(test_dataloader)\n",
    "    return taccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TsP57VG8KEfP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [02:04<00:00,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û—Ü–µ–Ω–∫–∞ –∑–∞ —ç—Ç–æ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∏—Ç 9.42 –±–∞–ª–ª–æ–≤\n",
      "tensor(0.4145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = evaluate_task(model, val_dataloader)\n",
    "print(f\"–û—Ü–µ–Ω–∫–∞ –∑–∞ —ç—Ç–æ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∏—Ç {np.clip(10 * accuracy_score / 0.44, 0, 10):.2f} –±–∞–ª–ª–æ–≤\")\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=False, num_classes=200)\n",
    "#resnet = torchvision.models.resnet18(pretrained=False, num_classes=200)\n",
    "#num_classes = 200  # –ó–∞–¥–∞–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –≤–∞—à–µ–π –∑–∞–¥–∞—á–∏\n",
    "#resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "wandb_logger = WandbLogger\\\n",
    "    (log_model='all') # –∫–∞–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–∞–µ—Ç —Å pytorch_lightning https://docs.wandb.ai/guides/integrations/lightning\n",
    "\n",
    "model = resnet#YourNet(dropout=0.4)\n",
    "module = YourModule(model) # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:45pozuf9) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:45pozuf9). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fcc0f13d48d457180ebcbb03da8fdbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01115096805539603, max=1.0)‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"resnet18+Lion+entr+256+factor0.1\"\n",
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç\n",
    "wandb.init(project=\"hw_02_exs1\", name=name)\n",
    "# —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∫–∏ –≤ wandb + –ø—Ä–æ—Å–∏–º —Å–ª–µ–¥–∏—Ç—å –∑–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ —Å–µ—Ç–∫–∏\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | ResNet | 11.3 M\n",
      "---------------------------------\n",
      "11.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.116    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d2a0e6806d48d681b9947e3bdd6308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbedb4c4379246ea8fff5fc9a4247606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c130cff9064841a6b5e07be36c4eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61db0e31bcbd4caeaa5484665a2c9d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e995d29dda44a8b9d7e84a1235c878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfe8a4296044486aefa8d4ef5d7d1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5efd89356ce4660a24e340f9d379449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9023ac6f818f4d9da761a134f8c0c02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae885ea07114ac4a29f7f18ff82b3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3d1dd62a0241e682e347ed663b81c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f8fe0013ec4ba39db8792fd8b55f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecc93035cf6466ca57422d6e252dc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69329be2f72b478db5808dd4c04b33fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b36810c307b4555b33c4f544fe2ec2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de66e0da46a54ceca4201953e35a67c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e367d153674bddbf42fa30c75c5881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94c735fc67b48698bdfafcad349f0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e422871544f04441885289610442ff51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716f494d9b894bf5b3ed73aa207afd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79207c4e14d4dd4b30412afee0958e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f6527d3c1d475389d01bed93260387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb7215abe4d4ca9a2a3adb98f4fd0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=wandb_logger, max_epochs=20)\n",
    "trainer.fit(module, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [01:14<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û—Ü–µ–Ω–∫–∞ –∑–∞ —ç—Ç–æ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∏—Ç 10.00 –±–∞–ª–ª–æ–≤\n",
      "tensor(0.4536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = evaluate_task(model, val_dataloader)\n",
    "print(f\"–û—Ü–µ–Ω–∫–∞ –∑–∞ —ç—Ç–æ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∏—Ç {np.clip(10 * accuracy_score / 0.44, 0, 10):.2f} –±–∞–ª–ª–æ–≤\")\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–π—Ç–µ –∫–ª–∞—Å—Å, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç nn.Module –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —Å–≤–æ—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ ResNet-18\n",
    "class CustomResNet18(torchvision.models.resnet18):\n",
    "    def __init__(self):\n",
    "        super(CustomResNet18, self).__init__(pretrained=False, num_classes=200)\n",
    "        \n",
    "        for name, module in self.named_children():\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                setattr(self, name, nn.SELU)\n",
    "\n",
    "    def __init__(self, replace_relu_with):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å ResNet-18 –∏–∑ torchvision\n",
    "        resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "        \n",
    "        # –£–¥–∞–ª–∏—Ç–µ –≤—Å–µ —Å–ª–æ–∏ ReLU –∏ –∑–∞–º–µ–Ω–∏—Ç–µ –∏—Ö –Ω–∞ –¥—Ä—É–≥—É—é –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å\n",
    "        for name, module in resnet18.named_children():\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                setattr(resnet18, name, replace_relu_with())\n",
    "        \n",
    "        # –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –≤—Å–µ —Å–ª–æ–∏ –∏–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "        self.features = nn.Sequential(*list(resnet18.children())[:-2])  # –£–¥–∞–ª–∏—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–≤–∞ —Å–ª–æ—è\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, 1000)  # –ó–∞–º–µ–Ω–∏—Ç–µ –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# –ó–∞–º–µ–Ω–∏—Ç–µ ReLU –Ω–∞ –¥—Ä—É–≥—É—é –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä, Sigmoid\n",
    "def replace_relu_with_sigmoid():\n",
    "    return nn.Sigmoid()\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∞—à—É –∫–∞—Å—Ç–æ–º–Ω—É—é –º–æ–¥–µ–ª—å\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_resnet = CustomResNet18(replace_relu_with_sigmoid)\n",
    "#resnet = torchvision.models.resnet18(pretrained=False, num_classes=200)\n",
    "#num_classes = 200  # –ó–∞–¥–∞–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –≤–∞—à–µ–π –∑–∞–¥–∞—á–∏\n",
    "#resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "wandb_logger = WandbLogger\\\n",
    "    (log_model='all') # –∫–∞–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–∞–µ—Ç —Å pytorch_lightning https://docs.wandb.ai/guides/integrations/lightning\n",
    "\n",
    "model = resnet#YourNet(dropout=0.4)\n",
    "module = YourModule(model) # YOUR CODE HERE\n",
    "\n",
    "name = \"resnet18+Lion+entr+512+randaug+LambdaLR\"\n",
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç\n",
    "wandb.init(project=\"hw_02_exs1\", name=name)\n",
    "# —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∫–∏ –≤ wandb + –ø—Ä–æ—Å–∏–º —Å–ª–µ–¥–∏—Ç—å –∑–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ —Å–µ—Ç–∫–∏\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(logger=wandb_logger, max_epochs=13)\n",
    "trainer.fit(module, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = evaluate_task(model, val_dataloader)\n",
    "print(f\"–û—Ü–µ–Ω–∫–∞ –∑–∞ —ç—Ç–æ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∏—Ç {np.clip(10 * accuracy_score / 0.44, 0, 10):.2f} –±–∞–ª–ª–æ–≤\")\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=200, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=False, num_classes=200)\n",
    "resnet.state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–µ –º–æ–¥–µ–ª–∏ ResNet50-200 —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ –æ–±—É—á–∞—é—Ç—Å—è. –¢–æ –∂–µ –º–æ–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å –ø—Ä–æ –º–µ–Ω—å—à–∏–π batch_size, –Ω–∞–ø—Ä–∏–º–µ—Ä 64, 128, –∞ —Ç–∞–∫–∂–µ –∏–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã (AdamW). \n",
    "InseptonV3, ResNext50_32x4d, ConvNext_tiny - –≤—Å–µ –æ–Ω–∏ –ª–∏–±–æ –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏, –ª–∏–±–æ —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZqSdlQQKukS"
   },
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 2\n",
    "\n",
    "5 –±–∞–ª–ª–æ–≤\n",
    "–î–æ–±–µ–π—Ç–µ—Å—å accuracy –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –Ω–µ –º–µ–Ω–µ–µ 0.84. –í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –¥–µ–ª–∞—Ç—å —Ä–µ—Å–∞–π–∑ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ—Ç—Ä–µ–π–Ω –º–æ–∂–Ω–æ.\n",
    "\n",
    "–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –≤—ã–±–∏—Ç—å —Å–∫–æ—Ä (—Å—á–∏—Ç–∞–µ—Ç—Å—è –Ω–∏–∂–µ) –Ω–∞ 2.5/5 –±–∞–ª–ª–∞ (—Ç–æ –µ—Å—Ç—å –ø–æ–ª–æ–≤–∏–Ω—É –∑–∞ –∑–∞–¥–∞–Ω–∏–µ) –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–æ–±–ª—é–¥–∞—Ç—å –ø–∞—Ä—É –ø—Ä–æ—Å—Ç—ã—Ö –∂–∏–∑–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª:\n",
    "1. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–±–µ–∑ –Ω–µ–µ —Å–ª–æ–∂–Ω–æ –æ—á–µ–Ω—å –±—É–¥–µ—Ç)\n",
    "2. –û–ø—Ç–∏–º–∞–π–∑–µ—Ä—ã –º–æ–∂–Ω–æ (–∏ –Ω—É–∂–Ω–æ) –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º. –û–¥–Ω–∞–∫–æ –∫–æ–≥–¥–∞ —á—Ç–æ-—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç–µ, —Ç–æ –Ω–µ –º–µ–Ω—è–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—Ä–∞–∑—É - —Å–æ–±—å–µ—Ç–µ –ª–æ–≥–∏–∫—É —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
    "3. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–ª–∏ —Å–∞–º—ã–µ –ø–µ—Ä–≤—ã–µ —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (—á—Ç–æ –Ω–∞ –ª–µ–∫—Ü–∏—è—Ö –≤—Å—Ç—Ä–µ—á–∞–ª–∏—Å—å –∏–ª–∏ –º–æ–∂–µ—Ç–µ –ø–æ–π—Ç–∏ –¥–∞–ª—å—à–µ).\n",
    "4. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–∞—á–∞–ª–∞ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∫–∞–∫ baseline. –û—Ç—Å—é–¥–∞ –ø–æ–π–º–µ—Ç–µ –∫–∞–∫–∏–µ —Å–ª–æ–∏ –Ω—É–∂–Ω–æ –¥–æ–æ–±—É—á–∞—Ç—å.\n",
    "5. –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Å–µ –Ω–æ—É—Ç–±—É–∫–∏ –ø—Ä–æ—à–µ–¥—à–∏—Ö —Å–µ–º–∏–Ω–∞—Ä–æ–≤ –∏ —Å–ª–µ–ø–∏—Ç—å –∏–∑ –Ω–∏—Ö —á—Ç–æ-—Ç–æ –æ–±—â–µ–µ. –°–µ–º–∏–Ω–∞—Ä—Å–∫–∏—Ö —Ç–µ—Ç—Ä–∞–¥–æ–∫ —Ö–≤–∞—Ç–∏—Ç —Å–≤–µ—Ä—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.disable_beta_transforms_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform_img = transforms.Compose([\n",
    "    v2.Resize(112),\n",
    "    v2.RandomApply(transforms=[transforms.AutoAugment()], p=0.5),\n",
    "    v2.RandomApply(transforms=[transforms.AugMix()], p=0.2),\n",
    "    v2.RandomApply(transforms=[transforms.Grayscale(num_output_channels=3)], p=0.1),\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder('/Users/nikitaevseev/Desktop/DS/DL/dataset/dataset/train', transform=transform_img)\n",
    "\n",
    "train_dataset_loader = DataLoader(train_dataset, batch_size=len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std(loader):\n",
    "  images, lebels = next(iter(loader))\n",
    "  mean, std = images.mean([0,2,3]), images.std([0,2,3])\n",
    "  return mean, std\n",
    "mean, std = mean_std(train_dataset_loader)\n",
    "print(\"mean and std: \\n\", mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# YOU CAN DEFINE AUGMENTATIONS HERE\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomApply(transforms=[transforms.ColorJitter(brightness=1.0, contrast=0.5, saturation=1, hue=0.1)], p=0.2),\n",
    "        #v2.Resize(224),\n",
    "        v2.RandomApply(transforms=[transforms.AutoAugment()], p=0.5),\n",
    "        #v2.RandomApply(transforms=[transforms.AugMix()], p=0.2),\n",
    "        #v2.RandomApply(transforms=[transforms.Grayscale(num_output_channels=3)], p=0.1),\n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize(mean=[0.4687, 0.4491, 0.4163], std=[0.2716, 0.2662, 0.2772])\n",
    "    ]\n",
    ")\n",
    "#(0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)                    [0.485, 0.456, 0.406] [0.229, 0.224, 0.225]\n",
    "# mean=[0.4802, 0.4481, 0.3975], std=[0.2770, 0.2691, 0.2821]\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        #v2.Resize(224),\n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize(mean=[0.4687, 0.4491, 0.4163], std=[0.2716, 0.2662, 0.2772])\n",
    "    ]\n",
    ")\n",
    "\n",
    "#applier = transforms.RandomApply(transforms=[AugMix], p=0.5)\n",
    "\n",
    "#transforms = transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(), ]), p=0.3)\n",
    "\n",
    "train_dataset = ImageFolder('/Users/nikitaevseev/Desktop/DS/DL/dataset/dataset/train', transform=train_transform)\n",
    "val_dataset = ImageFolder('/Users/nikitaevseev/Desktop/DS/DL/dataset/dataset/val', transform=val_transform)\n",
    "# REPLACE ./dataset/dataset WITH THE FOLDER WHERE YOU DOWNLOADED AND UNZIPPED THE DATASET\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=7, persistent_workers=True, multiprocessing_context='forkserver')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=7, persistent_workers=True, multiprocessing_context='forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests passed\n"
     ]
    }
   ],
   "source": [
    "# Just very simple sanity checks\n",
    "assert isinstance(train_dataset[0], tuple)\n",
    "assert len(train_dataset[0]) == 2\n",
    "assert isinstance(train_dataset[1][1], int)\n",
    "print(\"tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_dataloader:\n",
    "    images, class_nums = batch\n",
    "    plt.imshow(images[5].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    plt.imshow(images[15].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDzXM5rNxNQp"
   },
   "source": [
    "### –ú–æ–¥–µ–ª—å (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDr9l76AxH_9"
   },
   "outputs": [],
   "source": [
    "class YourNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def _forward(self, x):\n",
    "        # runs the Neural Network\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def get_accuracy(self, reset=False):\n",
    "        # YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Flwqk0YjxPLE"
   },
   "source": [
    "### –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –∫–ª–∞—Å—Å lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UnKHluO6xID4"
   },
   "outputs": [],
   "source": [
    "class YourModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-4, wd=10.0):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.wd = wd\n",
    "\n",
    "    def forward(self, x):\n",
    "        result = self.model(x)\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        #optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate*10)\n",
    "        optimizer = Lion(self.parameters(), lr=self.learning_rate, weight_decay=self.wd)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {#LambdaLR(optimizer, lr_lambda=lambda epoch: 0.85 ** epoch)}\n",
    "                \"scheduler\": ReduceLROnPlateau(optimizer, factor=0.1, patience=1),\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"frequency\": 1   \n",
    "                },\n",
    "        }\n",
    "        \n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        images, target = train_batch\n",
    "        output = self.model(images)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, prog_bar=True\n",
    "        )  # —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–≥–∏ –≤ –ø–∞–ø–∫—É, –Ω–æ –º–æ–∂–Ω–æ –Ω–µ—Å–ª–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å wandb\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        images, target = val_batch\n",
    "        #loss = self.model(images, target)\n",
    "        output = self.model(images)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        pred = torch.argmax(output, dim=-1)\n",
    "        acc_batch = accuracy(pred.long(), target, task='multiclass', num_classes=200)\n",
    "        self.log(\"acc\", acc_batch, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Base_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Base_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /Users/nikitaevseev/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 338M/338M [00:32<00:00, 11.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.convnext_base(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.014285714285714285, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02857142857142857, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04285714285714286, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05714285714285714, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07142857142857142, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08571428571428572, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11428571428571428, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12857142857142856, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14285714285714285, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15714285714285714, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17142857142857143, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18571428571428572, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "      )\n",
       "      (9): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.21428571428571427, mode=row)\n",
       "      )\n",
       "      (10): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.22857142857142856, mode=row)\n",
       "      )\n",
       "      (11): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.24285714285714285, mode=row)\n",
       "      )\n",
       "      (12): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2571428571428571, mode=row)\n",
       "      )\n",
       "      (13): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2714285714285714, mode=row)\n",
       "      )\n",
       "      (14): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2857142857142857, mode=row)\n",
       "      )\n",
       "      (15): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "      )\n",
       "      (16): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3142857142857143, mode=row)\n",
       "      )\n",
       "      (17): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.32857142857142857, mode=row)\n",
       "      )\n",
       "      (18): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.34285714285714286, mode=row)\n",
       "      )\n",
       "      (19): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.35714285714285715, mode=row)\n",
       "      )\n",
       "      (20): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.37142857142857144, mode=row)\n",
       "      )\n",
       "      (21): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.38571428571428573, mode=row)\n",
       "      )\n",
       "      (22): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4, mode=row)\n",
       "      )\n",
       "      (23): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4142857142857143, mode=row)\n",
       "      )\n",
       "      (24): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.42857142857142855, mode=row)\n",
       "      )\n",
       "      (25): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.44285714285714284, mode=row)\n",
       "      )\n",
       "      (26): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.45714285714285713, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4714285714285714, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4857142857142857, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=200, bias=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.classifier[2] = nn.Linear(in_features=resnet.classifier[2].in_features, out_features=200, bias=True)\n",
    "resnet.classifier[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.heads.head = nn.Linear(in_features=resnet.heads.head.in_features, out_features=200, bias=True)\n",
    "resnet.heads.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.fc = nn.Linear(in_features=resnet.fc.in_features, out_features=200, bias=True)\n",
    "resnet.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:d2a80vj8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72566a7c816647c282bc183e1a44a939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vit_b_16+Lion+256+224^2</strong> at: <a href='https://wandb.ai/naevseev-work/hw_02_exs2/runs/d2a80vj8' target=\"_blank\">https://wandb.ai/naevseev-work/hw_02_exs2/runs/d2a80vj8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231111_200031-d2a80vj8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:d2a80vj8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a116828fa92f4dca872c7983ebb8f03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011167503233365197, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nikitaevseev/Desktop/DS/DL/wandb/run-20231111_203104-uqdazmjl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/naevseev-work/hw_02_exs2/runs/uqdazmjl' target=\"_blank\">convnext_base+Lion+256+64^2</a></strong> to <a href='https://wandb.ai/naevseev-work/hw_02_exs2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/naevseev-work/hw_02_exs2' target=\"_blank\">https://wandb.ai/naevseev-work/hw_02_exs2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/naevseev-work/hw_02_exs2/runs/uqdazmjl' target=\"_blank\">https://wandb.ai/naevseev-work/hw_02_exs2/runs/uqdazmjl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name  | Type     | Params\n",
      "-----------------------------------\n",
      "0 | model | ConvNeXt | 87.8 M\n",
      "-----------------------------------\n",
      "87.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.8 M    Total params\n",
      "351.086   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6670e48c7df46b38b99e7c827599c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/nikitaevseev/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ea20ab7d3647ee9123c6a0fcf52229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 7.91 GB, other allocations: 1.17 GB, max allowed: 9.07 GB). Tried to allocate 8.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb –Ø—á–µ–π–∫–∞ 61\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m wandb\u001b[39m.\u001b[39mwatch(model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m, logger\u001b[39m=\u001b[39mwandb_logger, max_epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(module, train_dataloader, val_dataloader)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    544\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m call\u001b[39m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    546\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    547\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    576\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    577\u001b[0m     ckpt_path,\n\u001b[1;32m    578\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m )\n\u001b[0;32m--> 581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(model, ckpt_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[1;32m    583\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    584\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    987\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 990\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_stage()\n\u001b[1;32m    992\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    995\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1036\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1035\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1036\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n\u001b[1;32m   1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:359\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_loop\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:136\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    135\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(data_fetcher)\n\u001b[1;32m    137\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    138\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:240\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    239\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautomatic_optimization\u001b[39m.\u001b[39mrun(trainer\u001b[39m.\u001b[39moptimizers[\u001b[39m0\u001b[39m], batch_idx, kwargs)\n\u001b[1;32m    241\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:187\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         closure()\n\u001b[1;32m    182\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step(batch_idx, closure)\n\u001b[1;32m    189\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    190\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:265\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    264\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m call\u001b[39m.\u001b[39m_call_lightning_module_hook(\n\u001b[1;32m    266\u001b[0m     trainer,\n\u001b[1;32m    267\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moptimizer_step\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    268\u001b[0m     trainer\u001b[39m.\u001b[39mcurrent_epoch,\n\u001b[1;32m    269\u001b[0m     batch_idx,\n\u001b[1;32m    270\u001b[0m     optimizer,\n\u001b[1;32m    271\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    275\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m    156\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    159\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    160\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1282\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1244\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1245\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1249\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m \u001b[39m    the optimizer.\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \n\u001b[1;32m   1281\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m     optimizer\u001b[39m.\u001b[39mstep(closure\u001b[39m=\u001b[39moptimizer_closure)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:151\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy\u001b[39m.\u001b[39moptimizer_step(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer, closure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:230\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 230\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39moptimizer_step(optimizer, model\u001b[39m=\u001b[39mmodel, closure\u001b[39m=\u001b[39mclosure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:117\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39mstep(closure\u001b[39m=\u001b[39mclosure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lion_pytorch/lion_pytorch.py:64\u001b[0m, in \u001b[0;36mLion.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m exists(closure):\n\u001b[1;32m     63\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m---> 64\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m     67\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m p: exists(p\u001b[39m.\u001b[39mgrad), group[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:104\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m     92\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     93\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     96\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     97\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m    hook is called.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclosure(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:126\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39menable_grad()\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 126\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step_fn()\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[1;32m    314\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m training_step_output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39m\u001b[39mtraining_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39mkwargs\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    316\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()  \u001b[39m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_result_cls\u001b[39m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[39m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:382\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module:\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_redirection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39m\"\u001b[39m\u001b[39mtraining_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 382\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mtraining_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32m/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb –Ø—á–µ–π–∫–∞ 61\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_step\u001b[39m(\u001b[39mself\u001b[39m, train_batch, batch_idx):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     images, target \u001b[39m=\u001b[39m train_batch\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(images)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()(output, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m\"\u001b[39m, loss, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikitaevseev/Desktop/DS/DL/DL_hw_02.ipynb#Y121sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     )  \u001b[39m# —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–≥–∏ –≤ –ø–∞–ø–∫—É, –Ω–æ –º–æ–∂–Ω–æ –Ω–µ—Å–ª–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å wandb\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/convnext.py:176\u001b[0m, in \u001b[0;36mConvNeXt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/convnext.py:170\u001b[0m, in \u001b[0;36mConvNeXt._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 170\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures(x)\n\u001b[1;32m    171\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    172\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/models/convnext.py:64\u001b[0m, in \u001b[0;36mCNBlock.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     63\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_scale \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock(\u001b[39minput\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(result)\n\u001b[1;32m     65\u001b[0m     result \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/ops/stochastic_depth.py:62\u001b[0m, in \u001b[0;36mStochasticDepth.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mreturn\u001b[39;00m stochastic_depth(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/ops/stochastic_depth.py:44\u001b[0m, in \u001b[0;36mstochastic_depth\u001b[0;34m(input, p, mode, training)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mif\u001b[39;00m survival_rate \u001b[39m>\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m     43\u001b[0m     noise\u001b[39m.\u001b[39mdiv_(survival_rate)\n\u001b[0;32m---> 44\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39m*\u001b[39m noise\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 7.91 GB, other allocations: 1.17 GB, max allowed: 9.07 GB). Tried to allocate 8.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger\\\n",
    "    (log_model='all') # –∫–∞–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–∞–µ—Ç —Å pytorch_lightning https://docs.wandb.ai/guides/integrations/lightning\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "model = resnet#YourNet(dropout=0.4)\n",
    "module = YourModule(model) # YOUR CODE HERE\n",
    "name = \"convnext_base+Lion+256+64^2\"\n",
    "# –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç\n",
    "wandb.init(project=\"hw_02_exs2\", name=name)\n",
    "# —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∫–∏ –≤ wandb + –ø—Ä–æ—Å–∏–º —Å–ª–µ–¥–∏—Ç—å –∑–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏ —Å–µ—Ç–∫–∏\n",
    "wandb.watch(model)\n",
    "trainer = pl.Trainer(accelerator=\"auto\", logger=wandb_logger, max_epochs=20)\n",
    "trainer.fit(module, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5D2bwOKSHVp"
   },
   "source": [
    "### –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–¥–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_task(model, test_dataloader):\n",
    "    model = model\n",
    "    model.eval()\n",
    "    taccuracy = 0.0\n",
    "    for images, labels in tqdm(test_dataloader):\n",
    "        images, labels = images, labels\n",
    "        with torch.no_grad():\n",
    "            #loss = model(images, labels)\n",
    "            output = model(images)\n",
    "            loss = torch.nn.CrossEntropyLoss()(output, labels)\n",
    "            targets = labels\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            preds = pred\n",
    "            acc_batch = accuracy(preds.long(), targets.long(), task='multiclass', num_classes=200)\n",
    "        taccuracy += acc_batch\n",
    "    taccuracy = taccuracy / len(test_dataloader)\n",
    "    return taccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEdwJE5uOrIM"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate_task(model, val_dataloader)\n",
    "print(f\"–û—Ü–µ–Ω–∫–∞ –∑–∞ —ç—Ç–æ –∑–∞–¥–∞–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–∏—Ç {np.clip(10 * (accuracy - 0.5) / 0.34, 0, 10):.2f} –±–∞–ª–ª–æ–≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 15,
    "id": "pT8vfPSolRVb"
   },
   "source": [
    "# –û—Ç—á—ë—Ç –æ–± —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö \n",
    "\n",
    "—Ç–µ–∫—Å—Ç –ø–∏—Å–∞—Ç—å —Ç—É—Ç (–∏–ª–∏ —Å—Å—ã–ª–æ—á–∫—É –Ω–∞ wandb/–ª—é–±–æ–π —Ç—Ä–µ–∫–µ—Ä —ç–∫—Å–ø—Ä–µ–∏–º–µ–Ω—Ç–æ–≤) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è, —Ç–æ –µ—Å—Ç—å –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏–º–µ–Ω–Ω–æ —Ç—É—Ç —Ä–∏—Å–æ–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏, –µ—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –≥–æ—Ç–æ–≤—ã–µ —Ç—Ä–µ–∫–µ—Ä—ã/–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∏ –≤–∞—à–∏—Ö –º–æ–¥–µ–ª–µ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkGZ3kuULB55"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "max_cell_id": 35
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
